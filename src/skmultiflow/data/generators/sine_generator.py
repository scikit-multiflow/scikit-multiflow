import numpy as np
from skmultiflow.data.base_stream import Stream
from skmultiflow.core.utils.validation import check_random_state


class SineGenerator(Stream):
    """ SineGenerator

    This generator is an implementation of the dara stream with abrupt
    concept drift, as described in Gama, Joao, et al.'s 'Learning with drift
    detection.' Advances in artificial intelligenceâ€“SBIA 2004. Springer Berlin
    Heidelberg, 2004. 286-295."

    It generates up to 4 relevant numerical attributes, that vary from 0 to 1,
    where only 2 of them are relevant to the classification task and the other
    2 are added by request of the user. A classification function is chosen
    among four possible ones:

        0-SINE1. Abrupt concept drift, noise-free examples. It has two relevant
    attributes. Each attributes has values uniformly distributed in [0; 1]. In
    the first context all points below the curve y = sin(x) are classified as
    positive.
        1- Reversed SINIE1. The reversed classification of SINE1.
        2.SINE2. The same two relevant attributes. The classification function
    is y < 0.5 + 0.3 sin(3 * PI * x).
        3-Reversed SINIE1. The reversed classification of SINE2.

    Concept drift is possible if used in conjunction with the concept
    drift generator, that at the time of this framework's first release
    is not yet implemented. The abrupt drift is generated by changing
    the classification function, thus changing the threshold.

    Two important features are the possibility to balance classes, which
    means the class distribution will tend to a uniform one, and the possibility
    to add noise, which will, add two non relevant attributes.

    Parameters
    ----------
    classification_function: int (Default: 0)
        Which of the four classification functions to use for the generation.
        The value can vary from 0 to 3.

    sample_seed: int (Default: None)
        The seed used to initialize the random generator, which is an instance
        of numpy's random.

    balance_classes: bool (Default: False)
        Whether to balance classes or not. If balanced, the class distribution
        will converge to a uniform distribution.

    add_noise: bool (Default: False)
        Adds 2 non relevant attributes to the stream.

    Notes
    -----
    Concept drift is not yet available, since the support class that adds
    the drift is not yet implemented.

        Examples
    --------
    >>> # Imports
    >>> from skmultiflow.data.generators.sine_generator import SineGenerator
    >>> # Setting up the stream
    >>> stream = SineGenerator(classification_function = 2, sample_seed = 112, balance_classes = False,
    ... add_noise = True)
    >>> stream.prepare_for_use()
    >>> # Retrieving one sample
    >>> stream.next_sample()
    (array([[0.37505713, 0.64030462, 0.95001658, 0.0756772 ]]), array([1.]))
    >>> stream.next_sample(10)
    (array([[0.77692966, 0.83274576, 0.05480574, 0.81767738],
       [0.88535146, 0.72234651, 0.00255603, 0.98119928],
       [0.34341985, 0.09475989, 0.39464259, 0.00494492],
       [0.73670683, 0.95580687, 0.82060937, 0.344983  ],
       [0.37854446, 0.78476361, 0.08623151, 0.54607394],
       [0.16222602, 0.29006973, 0.04500817, 0.33218776],
       [0.73653322, 0.83921149, 0.70936161, 0.18840112],
       [0.98566856, 0.38800331, 0.50315448, 0.76353033],
       [0.68373245, 0.72195738, 0.21415209, 0.76309258],
       [0.07521616, 0.6108907 , 0.42563042, 0.23435109]]), array([1., 0., 1., 0., 1., 1., 1., 0., 0., 1.]))
    >>> stream.n_remaining_samples()
    -1
    >>> stream.has_more_samples()
    True

    """
    NUM_BASE_ATTRIBUTES = 2
    TOTAL_ATTRIBUTES_INCLUDING_NOISE = 4

    def __init__(self, classification_function=0, sample_seed=None, balance_classes=False, add_noise=False):
        super().__init__()

        # Classification functions to use
        self.classification_functions = [self.classification_function_zero, self.classification_function_one,
                                         self.classification_function_two, self.classification_function_three]
        self.classification_function_idx = classification_function
        self.sample_seed = sample_seed
        self.add_noise = add_noise
        self.balance_classes = balance_classes
        self.n_num_features = self.NUM_BASE_ATTRIBUTES
        self.n_classes = 2
        self.n_targets = 1
        self.sample_random = None
        self.next_class_should_be_zero = False

        self.__configure()

    def __configure(self):
        self.sample_random = None
        self.sample_random = check_random_state(self.sample_seed)
        self.next_class_should_be_zero = False
        if self.add_noise:
            self.n_num_features = self.TOTAL_ATTRIBUTES_INCLUDING_NOISE
        self.outputs_labels = ["class"]
        self.features_labels = ["att_num_" + str(i) for i in range(self.n_num_features)]

    def n_remaining_samples(self):
        return -1

    def has_more_samples(self):
        return True

    def next_sample(self, batch_size=1):
        """ next_sample

        The sample generation works as follows: The two attributes are
        generated with the random generator, initialized with the seed passed
        by the user. Then, the classification function decides whether to
        classify the instance as class 0 or class 1. The next step is to
        verify if the classes should be balanced, and if so, balance the
        classes. The last step is to add noise, if the add_noise is True.

        The generated sample will have 2 relevant features, and an additional
        two noise features if option chosen, and 1 label (it has one classification task).

        Parameters
        ----------
        batch_size: int
            The number of samples to return.

        Returns
        -------
        tuple or tuple list
            Return a tuple with the features matrix and the labels matrix for
            the batch_size samples that were requested.

        """

        data = np.zeros([batch_size, self.n_num_features + 1])

        for j in range(batch_size):
            att1 = att2 = 0.0
            group = 0
            desired_class_found = False
            while not desired_class_found:
                att1 = self.sample_random.rand()
                att2 = self.sample_random.rand()
                group = self.classification_functions[self.classification_function_idx](att1, att2)

                if not self.balance_classes:
                    desired_class_found = True
                else:
                    if (self.next_class_should_be_zero and (group == 0)) or \
                            ((not self.next_class_should_be_zero) and (group == 1)):
                        desired_class_found = True
                        self.next_class_should_be_zero = not self.next_class_should_be_zero

            data[j, 0] = att1
            data[j, 1] = att2

            if self.has_noise():
                for i in range(self.NUM_BASE_ATTRIBUTES, self.TOTAL_ATTRIBUTES_INCLUDING_NOISE):
                    data[j, i] = self.sample_random.rand()
                data[j, 4] = group
            else:
                data[j, 2] = group

        self.current_sample_x = data[:, :self.n_num_features]
        self.current_sample_y = data[:, self.n_num_features:].flatten()

        return self.current_sample_x, self.current_sample_y

    def prepare_for_use(self):
        self.restart()

    def is_restartable(self):
        return True

    def restart(self):
        self.sample_random.seed(self.sample_seed)
        self.next_class_should_be_zero = False

    def has_noise(self):
        return self.add_noise

    def get_n_cat_features(self):
        return self.n_cat_features

    def get_n_num_features(self):
        return self.n_num_features

    def get_n_features(self):
        return self.n_num_features

    def get_n_targets(self):
        return self.n_targets

    def get_feature_names(self):
        return self.features_labels

    def get_target_names(self):
        return self.outputs_labels

    def last_sample(self):
        return self.current_sample_x, self.current_sample_y

    @staticmethod
    def classification_function_zero(att1, att2):
        """ classification_function_zero

        Decides the sample class label based on the sine of att2 and the
        threshold value of att1.


        Parameters
        ----------
        att1: float
            First numeric attribute.

        att2: float
            Second numeric attribute.

        Returns
        -------
        int
            Returns the sample class label, either 0 or 1.

        """
        return 0 if (att1 >= np.sin(att2)) else 1

    @staticmethod
    def classification_function_one(att1, att2):
        """ classification_function_one

        Decides the sample class label based on the att1 and the threshold
        value of sine att2.

        Parameters
        ----------
        att1: float
            First numeric attribute.

        att2: float
            Second numeric attribute.

        Returns
        -------
        int
            Returns the sample class label, either 0 or 1.

        """
        return 0 if (att1 < np.sin(att2)) else 1

    @staticmethod
    def classification_function_two(att1, att2):
        """ classification_function_two

        Decides the sample class label based on 0.5+0.3*np.sin(3*np.pi*att2)
        and the threshold value of att1.

        Parameters
        ----------
        att1: float
            First numeric attribute.

        att2: float
            Second numeric attribute.

        Returns
        -------
        int
            Returns the sample class label, either 0 or 1.

        """
        return 0 if (att1 >= 0.5+0.3*np.sin(3*np.pi*att2)) else 1

    @staticmethod
    def classification_function_three(att1, att2):
        """ classification_function_three

        Decides the sample class label based on the att1 and the threshold
        value of sine 0.5+0.3*np.sin(3*np.pi*att2).

        Parameters
        ----------
        att1: float
            First numeric attribute.

        att2: float
            Second numeric attribute.

        Returns
        -------
        int
            Returns the sample class label, either 0 or 1.

        """
        return 0 if (att1 < 0.5 + 0.3 * np.sin(3 * np.pi * att2)) else 1

    def get_name(self):
        return "Sine Generator - {} target, {} classes".format(self.n_targets, self.n_classes)

    def get_targets(self):
        return [i for i in range(self.n_classes)]

    def get_info(self):
        return 'SineGenerator: classification_function: ' + str(self.classification_function_idx) + \
               ' - sample_seed: ' + str(self.sample_seed) + \
               ' - balance_classes: ' + ('True' if self.balance_classes else 'False') + \
               ' - add_noise: ' + str(self.has_noise())

    def generate_drift(self):
        new_function = self.sample_random.randint(4)
        while new_function == self.classification_function_idx:
            new_function = self.sample_random.randint(4)
        self.classification_function_idx = new_function
