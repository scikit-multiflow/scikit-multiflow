{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from skmultiflow.meta import MultiOutputLearner\n",
    "from skmultiflow.core import Pipeline\n",
    "from skmultiflow.data import FileStream\n",
    "from skmultiflow.metrics import *\n",
    "from sklearn.linear_model.perceptron import Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    This demo tests the MOL learner on a file stream, which reads from \n",
    "    the music.csv file.\n",
    "\n",
    "    The test computes the performance of the MOL learner as well as \n",
    "    the time to create the structure and classify all the samples in \n",
    "    the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "logging.basicConfig(format='%(message)s', level=logging.INFO)\n",
    "\n",
    "# Setup the file stream\n",
    "stream = FileStream(\"https://raw.githubusercontent.com/scikit-multiflow/streaming-datasets/\"\n",
    "                    \"master/music.csv\", 0, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pre training on 150 samples\n",
      "Total 593 samples\n",
      "Evaluating...\n"
     ]
    }
   ],
   "source": [
    "# Setup the classifier, by default it uses Logistic Regression\n",
    "# classifier = MultiOutputLearner()\n",
    "# classifier = MultiOutputLearner(base_estimator=SGDClassifier(n_iter=100))\n",
    "classifier = MultiOutputLearner(base_estimator=Perceptron())\n",
    "\n",
    "# Setup the pipeline\n",
    "pipe = Pipeline([('classifier', classifier)])\n",
    "\n",
    "pretrain_size = 150\n",
    "logging.info('Pre training on %s samples', str(pretrain_size))\n",
    "logging.info('Total %s samples', str(stream.n_samples))\n",
    "X, y = stream.next_sample(pretrain_size)\n",
    "# classifier.fit(X, y)\n",
    "classes = stream.target_values\n",
    "classes_flat = list(set([item for sublist in classes for item in sublist]))\n",
    "pipe.partial_fit(X, y, classes=classes_flat)\n",
    "count = 0\n",
    "true_labels = []\n",
    "predicts = []\n",
    "init_time = timer()\n",
    "logging.info('Evaluating...')\n",
    "while stream.has_more_samples():\n",
    "    X, y = stream.next_sample()\n",
    "    # p = classifier.predict(X)\n",
    "    p = pipe.predict(X)\n",
    "    predicts.extend(p)\n",
    "    true_labels.extend(y)\n",
    "    count += 1\n",
    "perf = hamming_score(true_labels, predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation time: 14.847986674001731 s\n",
      "Total samples analyzed: 443\n",
      "The classifier's static Hamming score    : 0.709\n"
     ]
    }
   ],
   "source": [
    "logging.info('Evaluation time: %s s', str(timer() - init_time))\n",
    "logging.info('Total samples analyzed: %s', str(count))\n",
    "logging.info('The classifier\\'s static Hamming score    : %0.3f' % perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
